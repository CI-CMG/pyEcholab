# coding=utf-8

#    National Oceanic and Atmospheric Administration
#    Alaskan Fisheries Science Center
#    Resource Assessment and Conservation Engineering
#    Midwater Assessment and Conservation Engineering

# THIS SOFTWARE AND ITS DOCUMENTATION ARE CONSIDERED TO BE IN THE PUBLIC DOMAIN
# AND THUS ARE AVAILABLE FOR UNRESTRICTED PUBLIC USE. THEY ARE FURNISHED "AS
# IS." THE AUTHORS, THE UNITED STATES GOVERNMENT, ITS INSTRUMENTALITIES,
# OFFICERS, EMPLOYEES, AND AGENTS MAKE NO WARRANTY, EXPRESS OR IMPLIED, AS TO
# THE USEFULNESS OF THE SOFTWARE AND DOCUMENTATION FOR ANY PURPOSE.  THEY
# ASSUME NO RESPONSIBILITY (1) FOR THE USE OF THE SOFTWARE AND DOCUMENTATION;
# OR (2) TO PROVIDE TECHNICAL SUPPORT TO USERS.

'''
.. module:: echolab2.instruments.EK80

    :synopsis:  A high-level interface for reading SIMRAD ".raw" formatted
                files written by the Simrad EK80 WBES system


| Developed by:  Zac Berkowitz <zac.berkowitz@gmail.com> under contract for
| National Oceanic and Atmospheric Administration (NOAA)
| Alaska Fisheries Science Center (AFSC)
| Midwater Assesment and Conservation Engineering Group (MACE)
|
| Authors:
|       Zac Berkowitz <zac.berkowitz@gmail.com>
|       Rick Towler   <rick.towler@noaa.gov>
| Maintained by:
|       Rick Towler   <rick.towler@noaa.gov>

$Id$
'''

"""

https://www.idtools.com.au/gpu-accelerated-fft-compatible-numpy/
"""


import os
import datetime
import numpy as np
from pytz import timezone
from .util.simrad_calibration import calibration
from .util.simrad_raw_file import RawSimradFile, SimradEOF
from .util.nmea_data import nmea_data
from .util.simrad_motion_data import simrad_motion_data
from .util import simrad_signal_proc
from ..ping_data import ping_data
from ..processing.processed_data import processed_data
from ..processing import line


class EK80(object):
    """This class is the 'file reader' class for Simrad EK80 instrument files.

    The EK80 class can read in one or more EK80 files and generates a raw_data
    class instance for each unique channel ID in the files. The class also
    contains numerous methods used to extract the raw sample data from one
    channel, or create processed_data objects containing.

    Attributes:
        start_time: Start_time is a datetime object that defines the start
            time of the data within the EK60 class
        end_time: End_time is a datetime object that defines the end time of
            the data within the EK60 class
        start_ping: Start_ping is an integer that defines the first ping of the
            data within the EK60 class.
        end_ping: End_ping is an integer that defines the last ping of
            the data within the EK60 class.
        n_pings: Integer value representing the total number of pings.
        frequencies: List of frequencies read from raw data files.
        channel_ids: List of stings identifying the unique channel IDs read
            from the instrument files.
        n_channels: Integer value representing the total number of
            channels in the class instance.
        raw_data: A dictionary that stores the raw_data objects, one for each
            unique channel in the files. The dictionary keys are the channel
            numbers.
        nmea_data: reference to a NmeaData class instance that will contain
            the NMEA data from the data files.
        read_incremental; Boolean value controlling whether files are read
            incrementally or all at once. The default value is False.
        store_angles: Boolean control variable to set whether or not to store
            angle data generated by EK60 GPTs.
        store_power: Boolean control variable to set whether or not to store
            the power data generated by EK60 GPTs.
        store_complex: Boolean control variable to set whether or not to store
            the complex data generated by EK80 WBTs.
        read_max_sample_count: Integer value to specify the max sample count
            to read. This property can be used to limit the number of samples
            read (and memory used) when your data of interest is less than
            the total number of samples contained in the EK60 files.
        read_start_time: Datetime object containing timestamp of the first
            ping to read if not reading all pings based on time.
        read_end_time: Datetime object containing timestamp of last ping to
            read if not reading all ping based on time.
        read_start_ping: Integer ping number of first ping to read if not
            reading all pings based on ping number.
        read_end_ping: Integer ping number of last ping to read if not
            reading all pings based on ping number.
        read_start_sample: Integer sample number of first sample to read if not
            reading all samples based on sample number.
        read_end_sample: Integer sample number of last sample to read if not
            reading all samples based on sample number.
        read_frequencies: List of floats (i.e. 18000.0) specifying the
            frequencies to read. An empty list will result in all frequencies
            being read.
        read_channel_ids = List of strings specifying the channel_ids
            (i,e, 'GPT  38 kHz 009072033fa2 1-1 ES38B') of the channels to
            read. An empty list will result in all channels being read.
    """

    def __init__(self):
        """Initializes EK80 class object.

        Creates and sets several internal properties used to store information
        about data and control operation of file reading with EK80 object
        instance. Code is heavily commented to facilitate use.
        """

        # Define EK80 properties.

        # These properties control what data are stored when reading
        # EK80 raw files. These properties can be manipulated directly or by
        # specifying them when calling the read and append methods.

        # Set store_angles to true to store angle data if any of the data files
        # contain data recorded from EK60 GPTs or WBT data saved in the reduced
        # power/angle format.
        self.store_angles = True

        # Set store_power to true to store power data if any of the data files
        # contain data recorded from EK60 GPTs or WBT data saved in the reduced
        # power/angle format.
        self.store_power = True

        # Set store_complex to true to store complex data if any of the data files
        # contain data recorded from EK80 WBTs saved as complex samples.
        self.store_complex = True

        # Specify the maximum sample count to read.  This property can be used
        # to limit the number of samples read (and memory used) when your data
        # of interest is large.
        self.read_max_sample_count = None

        # These params store any limits set on storing of data contained in
        # the raw files read. These parameters can be set directly, or through
        # many of the methods where you can specify start/end time or ping
        # and sample number.
        self.read_start_time = None
        self.read_end_time = None
        self.read_start_ping = None
        self.read_end_ping = None
        self.read_start_sample = None
        self.read_end_sample = None

        # read_frequencies can be set to a list of floats specifying the
        # frequencies to read. An empty list will result in all frequencies
        # being read.
        self.read_frequencies = []

        # read_channel_ids can be set to a list of strings specifying the
        # channel_ids of the channels to read. An empty list will result in all
        # channels being read.
        self.read_channel_ids = []

        #  initialize the data arrays
        self._init()


    def _init(self):
        '''_init is an internal method that initializes the data fields of
        the EK80 class.
        '''

        # The start_time and end_time will define the time span of the
        # data within the EK80 class.
        self.start_time = None
        self.end_time = None

        # The start_ping and end_ping will define the ping span of the data
        # within the EK80 class.
        self.start_ping = None
        self.end_ping = None

        # n_pings stores the total number of pings read.
        self.n_pings = 0

        # n_files stores the total number of raw files read.
        self.n_files = 0

        # A list of stings identifying the channel IDs that have been read.
        self.channel_ids = []

        # n_channels stores the total number of channels in the object.
        self.n_channels = 0

        # A dictionary to store the raw_data objects. The dictionary is keyed
        # by channel ID and each value is a list of raw_data objects associated
        # with that channel.
        self.raw_data = {}

        #  nmea_data stores the util.nmea_data object which will contain
        #  the NMEA data read from the raw file. This object has methods
        #  to extract, parse, and interpolate the NMEA data.
        self.nmea_data = nmea_data()

        #  motion_data is the util.simrad_motion_data object which will
        #  contain data from the MRU datagrams contained in the raw file.
        #  This object has methods to extract and interpolate the motion data.
        self.motion_data = simrad_motion_data()

        # annotation_data stores the contents of the TAG0 aka "annotation"
        # datagrams. Currently we're storing the raw dict returned by the
        # parser.
        self.annotation_data = []

        # data_array_dims contains the dimensions of the sample and angle or
        # complex data arrays specified as [n_pings, n_samples].  Values of
        # -1 specifythat the arrays will resize appropriately to contain all
        # pings and all samples read from the data source.  Setting values > 0
        # will create arrays that are fixed to that size.  Any samples beyond
        # the number specified as n_samples will be dropped.  When a ping is
        # added and the data arrays are full, the sample data will be rolled
        # such that the oldest data is dropped and the new ping is added.
        self._data_array_dims = [-1, -1]

        #  initialize the ping time - used to group "pings"
        self._this_ping_time = np.datetime64('1000-02')

        #  _last_progress stores the last reported progess through the current
        #  file in percent as integer.
        self._last_progress = -1

        #  initialize some internal attributes
        self._config = None
        self._filters = {}
        self._tx_params = {}
        self._environment = None


    def read_raw(self, *args, **kwargs):
        """Reads one or more Simrad EK80 .raw files into memory. Overwrites
        existing data (if any). The data are stored in an EK80.raw_data object.


        Args:
            raw_files (list): List containing full paths to data files to be
                read.
            power (bool): Controls whether power data is stored
            angles (bool): Controls whether angle data is stored
            complex (bool): Controls whether complex data is stored
            max_sample_count (int): Specify the max sample count to read
                if your data of interest is less than the total number of
                samples contained in the instrument files.
            start_time (str): Specify a start time if you do not want to read
                from the first ping. The format of the time string must
                match the format specified in time_format_string.
            end_time (str): Specify an end time if you do not want to read
                to the last ping. The format of the time string must
                match the format specified in time_format_string.
            start_ping (int): Specify starting ping number if you do not want
                to start reading at first ping.
            end_ping (int): Specify end ping number if you do not want
                to read all pings.
            frequencies (list): List of floats (i.e. 18000.0) if you
                only want to read specific frequencies.
            channel_ids (list): A list of strings that contain the unique
                channel IDs to read. If no list is supplied, all channels are
                read.
            time_format_string (str): String containing the format of the
                start and end time arguments. Format is used to create datetime
                objects from the start and end time strings
            start_sample (int): Specify starting sample number if not
                reading from first sample.
            end_sample (int): Specify ending sample number if not
                reading to last sample.
        """

        #  initialize the data arrays - this discards any previously read data.
        self._init()

        #  now call append_raw, passing on all arguments
        self.append_raw(*args, **kwargs)


    def append_raw(self, raw_files, power=None, angles=None, complex=None,
                 max_sample_count=None, start_time=None, end_time=None,
                 start_ping=None, end_ping=None, frequencies=None,
                 channel_ids=None, time_format_string='%Y-%m-%d %H:%M:%S',
                 incremental=None, start_sample=None, end_sample=None,
                 progress_callback=None):
        """Reads one or more Simrad EK80 .raw files and appends the data to any
        existing data. The data are ordered as read.


        Args:
            raw_files (list): List containing full paths to data files to be
                read.
            power (bool): Controls whether power data is stored
            angles (bool): Controls whether angle data is stored
            complex (bool): Controls whether complex data is stored
            max_sample_count (int): Specify the max sample count to read
                if your data of interest is less than the total number of
                samples contained in the instrument files.
            start_time (str): Specify a start time if you do not want to read
                from the first ping. The format of the time string must
                match the format specified in time_format_string.
            end_time (str): Specify an end time if you do not want to read
                to the last ping. The format of the time string must
                match the format specified in time_format_string.
            start_ping (int): Specify starting ping number if you do not want
                to start reading at first ping.
            end_ping (int): Specify end ping number if you do not want
                to read all pings.
            frequencies (list): List of floats (i.e. 18000.0) if you
                only want to read specific frequencies.
            channel_ids (list): A list of strings that contain the unique
                channel IDs to read. If no list is supplied, all channels are
                read.
            time_format_string (str): String containing the format of the
                start and end time arguments. Format is used to create datetime
                objects from the start and end time strings
            start_sample (int): Specify starting sample number if not
                reading from first sample.
            end_sample (int): Specify ending sample number if not
                reading to last sample.
        """

        # Update the reader state variables.
        if start_time:
            self.read_start_time = self._convert_time_bound(
                    start_time, format_string=time_format_string)
        if end_time:
            self.read_end_time = self._convert_time_bound(
                    end_time, format_string=time_format_string)
        if start_ping:
            self.read_start_ping = start_ping
        if end_ping:
            self.read_end_ping = end_ping
        if start_sample:
            self.read_start_sample = start_sample
        if end_sample:
            self.read_end_sample = end_sample
        if power:
            self.store_power = power
        if complex:
            self.store_complex = complex
        if angles:
            self.store_angles = angles
        if max_sample_count:
            self.read_max_sample_count = max_sample_count
        if frequencies:
            self.read_frequencies = frequencies
        if channel_ids:
            self.read_channel_ids = channel_ids

        # Ensure that the raw_files argument is a list.
        if isinstance(raw_files, str):
            raw_files = [raw_files]

        # Iterate through the list of .raw files to read.
        for filename in raw_files:
            #  reset attributes that store the most recent XML configuration datagram
            #  FIL filter datagrams, XML environment datagrams and XML parameter datagrams
            self._config = None
            self._filters = {}
            self._tx_params = {}
            self._environment = None

            #  get the total file size
            total_bytes = os.stat(filename).st_size

            #  normalize the file path and split out the parts
            filename = os.path.normpath(filename)
            file_parts = filename.split(os.path.sep)
            current_filename = file_parts[-1]
            current_filepath = os.path.sep.join(file_parts[0:-1])

            # open the raw file
            fid = RawSimradFile(filename, 'r')

            #  read the configuration datagram - this will always be the
            #  first datagram in an EK80 raw file.
            _config = self._read_config(fid)

            #  extract the per channel data into our internal config attribute
            #  and add some additional fields to each channel
            self._config = _config['configuration']
            for channel in self._config:
                self._config[channel]['file_name'] = current_filename
                self._config[channel]['file_path'] = current_filepath
                self._config[channel]['file_bytes'] = total_bytes
                self._config[channel]['start_time'] = _config['timestamp']
                self._config[channel]['start_ping'] = self.n_pings

            #  set the cumulative_bytes var and start time
            cumulative_bytes = _config['bytes_read']

            #  create a variable to track when we're done reading.
            finished = False

            #  and read datagrams until we're done
            while not finished:
                #  read a datagram - method returns some basic info
                dg_info = self._read_datagram(fid)

                #  call progress callback if supplied
                if (progress_callback):
                    #  determine the progress as an integer percent.
                    cumulative_bytes += dg_info['bytes_read']
                    cumulative_pct = round(cumulative_bytes / total_bytes * 100.)

                    #  call the callback when the percent changes
                    if cumulative_pct != self._last_progress:
                        #  call the provided callback - the callback has 3 args,
                        #  the first is the full path to the current file and the
                        #  second is the percent read and the third is the bytes read.
                        progress_callback(filename, cumulative_pct, cumulative_bytes)
                        self._last_progress = cumulative_pct

                #  update our finished state var - the file will be finished when
                #  the reader hits the end of the file or if end time/ping are
                #  set and we hit that point.
                finished = dg_info['finished']

        #  close the file
        fid.close()

        # Trim excess data from arrays after reading.
        for channel_id in self.channel_ids:
            for raw in self.raw_data[channel_id]:
                raw.trim()
        self.nmea_data.trim()
        self.motion_data.trim()


    def _read_config(self, fid):
        '''
        _read_config reads the raw file configuration datagram. It then checks if
        if there are any new channels it should be storing and if so, creates
        raw_data objects for those channels and updates some attributes.
        '''

        #  read the configuration datagram - this is the first datagram
        #  in an EK80 file.
        config_datagram = fid.read(1)
        config_datagram['timestamp'] = \
                np.datetime64(config_datagram['timestamp'], '[ms]')

        # check for any new channels and add them if required
        file_channels = config_datagram['configuration'].keys()
        for channel_id in file_channels:
            #  check if we're reading this channel
            if (not self.read_channel_ids or channel_id in self.read_channel_ids):
                #  check if we're reading this frequency
                frequency = config_datagram['configuration'][channel_id]['transducer_frequency']
                if (self.read_frequencies and frequency not in self.read_frequencies):
                    # There are specific frequencies specified and this
                    # is NOT one of them. Remove this channel from the config_datagram
                    # dictionary and continue.
                    config_datagram['configuration'].pop(channel_id)
                    continue

                #  we're reading this channel - check if it's new to us
                if channel_id not in self.raw_data:
                    # This is a new channel, create a list to store this
                    # channel's raw_data objects
                    self.raw_data[channel_id] = []

                    #  add the channel to our list of channel IDs
                    self.channel_ids.append(channel_id)

                    #  and increment the channel counter
                    self.n_channels += 1

                #  check if we need to create an entry for this channel's filters
                if channel_id not in self._filters:
                    #  and an empty dict to store this channel's filters
                    self._filters[channel_id] = {}

        #  return the configuration datagram dict
        return config_datagram


    def _read_datagram(self, fid):
        """Reads the next raw file datagram

        This method reads the next datagram from the file, storing the
        data contained in the datagram (if applicable), and returns a dict
        containing the number of bytes read, the datagramn timestamp, datagram
        type, and whether the reader is "finished". The finished flag will be set
        if end_time and/or end_ping is set in the reader and the datagram time
        is after the end time or the internal "ping" counter matches the
        specified end ping.

        Args:
            fid (file object): Pointer to currently open file object. This is a
                RawSimradFile file object and not the standard Python file
                object.
        """
        #  create the return dict that provides feedback on progress
        result = {'bytes_read':0, 'timestamp':None, 'type':None, 'finished':False}

        #  attempt to read the next datagram
        try:
            new_datagram = fid.read(1)
        except SimradEOF:
            #  we're at the end of the file
            result['finished'] = True
            return result

        # Convert the timestamp to a datetime64 object.
        new_datagram['timestamp'] = \
                np.datetime64(new_datagram['timestamp'], '[ms]')

        #  update the return dict properties
        result['timestamp'] = new_datagram['timestamp']
        result['bytes_read'] = new_datagram['bytes_read']
        result['type'] = new_datagram['type']

        # Check if data should be stored based on time bounds.
        if self.read_start_time is not None:
            if new_datagram['timestamp'] < self.read_start_time:
                #  we have a start time but this data comes before it
                #  so we return without doing anything else
                return result
        if self.read_end_time is not None:
            if new_datagram['timestamp'] > self.read_end_time:
                #  we have a end time and this data comes after it
                #  so we are actually done reading - set the finished
                #  field in our return dict and return
                result['finished'] = True
                return result

        #  update the ping counter
        if new_datagram['type'].startswith('RAW'):
            if self._this_ping_time != new_datagram['timestamp']:
                self.n_pings += 1
                self._this_ping_time = new_datagram['timestamp']

                # check if we'restoring this channel
                if new_datagram['channel_id'] not in self.channel_ids:
                    #  no, it's not in the list - just return
                    return result

        # Check if we should store this data based on ping bounds.
        if self.read_start_ping is not None:
            if self.n_pings < self.read_start_ping:
                #  we have a start ping but this data comes before it
                #  so we return without doing anything else
                return result
        if self.read_end_ping is not None:
            if self.n_pings > self.read_end_ping:
                #  we have a end ping and this data comes after it
                #  so we are actually done reading - set the finished
                #  field in our return dict and return
                result['finished'] = True
                return result

        # Update the end_time property.
        if self.end_time is not None:
            # We can't assume data will be read in time order.
            if self.end_time < new_datagram['timestamp']:
                self.end_time = new_datagram['timestamp']
        else:
            self.end_time = new_datagram['timestamp']

        # Process and store the datagrams by type.

        #  FIL datagrams store parameters used to filter the received signal
        #  EK80 class stores the filters for the currently being read file.
        #  Filters are stored by channel ID and then by filter stage
        if new_datagram['type'].startswith('FIL'):

            # Check if we're storing this channel
            if new_datagram['channel_id'] in self.channel_ids:

                #  add the filter parameters for this filter stage
                self._filters[new_datagram['channel_id']][new_datagram['stage']] = \
                        {'stage':new_datagram['stage'],
                         'n_coefficients':new_datagram['n_coefficients'],
                         'decimation_factor':new_datagram['decimation_factor'],
                         'coefficients':new_datagram['coefficients']}

        # RAW datagrams store raw acoustic data for a channel.
        elif new_datagram['type'].startswith('RAW'):

            #  check if we should set our start time property
            if not self.start_time:
                self.start_time = new_datagram['timestamp']
            # Set the first ping number we read.
            if not self.start_ping:
                self.start_ping = self.n_pings
            # Update the last ping number.
            self.end_ping = self.n_pings

            #  loop through the raw_data objects to find the raw_data object
            #  to store this data.
            this_raw_data = None
            for raw_obj in self.raw_data[new_datagram['channel_id']]:
                if raw_obj.data_type == '':
                    #  This raw_data object has no type so is empty and can store anything
                    this_raw_data = raw_obj
                    break
                if new_datagram['data_type'] <= 3 and raw_obj.data_type == 'power/angle':
                    # This raw_data object contains power/angle data and this datagram
                    # also contains power/angle data
                    this_raw_data = raw_obj
                    break
                if new_datagram['data_type'] > 3 and raw_obj.data_type == 'complex':
                    # This raw_data object contains complex data and this datagram
                    # also contains complex data
                    this_raw_data = raw_obj
                    break

            #  check if we need to create a new raw_data object
            if this_raw_data is None:
                #  create the new raw_data object
                this_raw_data = raw_data(new_datagram['channel_id'],
                        store_power=self.store_power,
                        store_angles=self.store_angles,
                        store_complex=self.store_complex,
                        max_sample_number=self.read_max_sample_count)
                # Set the transceiver type
                this_raw_data.transceiver_type = \
                        self._config[new_datagram['channel_id']]['transceiver_type']
                #  and add it to this channel's list of raw_data objects
                self.raw_data[new_datagram['channel_id']].append(this_raw_data)

            # Call this channel's append_ping method.
            this_raw_data.append_ping(new_datagram,
                    self._config[new_datagram['channel_id']], self._environment,
                    self._tx_params[new_datagram['channel_id']],
                    self._filters[new_datagram['channel_id']],
                    start_sample=self.read_start_sample,
                    end_sample=self.read_end_sample)

        # NME datagrams store ancillary data as NMEA-0183 style ASCII data.
        elif new_datagram['type'].startswith('NME'):
            # Add the datagram to our nmea_data object.
            self.nmea_data.add_datagram(new_datagram['timestamp'],
                    new_datagram['nmea_string'])

        # TAG datagrams contain time-stamped annotations inserted via the
        # recording software.
        elif new_datagram['type'].startswith('TAG'):
            # Currently we store the raw annotation datagrams. A bit rough
            # but you can get at what you need.
            self.annotation_data.append(new_datagram)

        # XML datagrams contain contain data encoded as an XML string.
        elif new_datagram['type'].startswith('XML'):
            #  XML datagrams have a subtype field identifying what
            #  kind of data they contain.
            if new_datagram['subtype'] == 'parameter':
                #  update the most recent parameter attribute for this channel
                self._tx_params[new_datagram[new_datagram['subtype']]['channel_id']] = \
                        new_datagram[new_datagram['subtype']]
            elif new_datagram['subtype'] == 'environment':
                #  update the most recent environment attribute
                self._environment = new_datagram[new_datagram['subtype']]

        # MRU datagrams contain vessel motion data
        elif new_datagram['type'].startswith('MRU'):
            # append this motion datagram to the motion_data object
            self.motion_data.add_datagram(new_datagram)

        else:
            #  report an unknown datagram type
            print("Unknown datagram type: " + str(new_datagram['type']))

        #  return our result dict which contains some basic info about
        #  the datagram we just read
        return result


    def _convert_time_bound(self, time, format_string):
        """Converts strings to datetime objects and normalizes to UTC.

        Internally, all times are datetime objects converted to UTC timezone.
        This method converts arguments to comply with this practice.

        Args:
            time (str or datetime): Either a string representing a date and
                time in format specified in format_string, or a datetime object.
            format_string (str): Format of time string specified in datetime
            object notations such as '%Y-%m-%d %H:%M:%S' to parse a time
            string of '2017-02-28 23:34:01'

        Returns:
            Datetime object normalized to UTC time.
        """
        # If given a datetime64[ms] object, there's nothing to convert.
        if time.dtype == '<M8[ms]':
            return

        utc = timezone('utc')

        # Convert string to datetime object.
        if isinstance(time, str):
            time = datetime.datetime.strptime(time, format_string)

        # Convert datetime object to UTC.
        if isinstance(time, datetime.datetime):
            time = utc.localize(time)

        return time


    def get_raw_data(self, channel_id=None):
        """Gets the raw data for a specific channel.

        This method returns a reference to the specified raw_data object for
        the specified channel id. If no channel id are specified, it returns a dictionary keyed by channel id
        containing all of the channels.

        Args:
            channel_id (str): The channel ID from which to return the raw data.

        Returns:
            Raw data object from the specified channel.
        """

        if channel_id is not None:
            # Channel id is specified.
            channel_data = self.raw_data.get(channel_id, None)
        else:
            # Channel id not specified - return all in a dictionary,
            # keyed by channel ID.
            channel_data = self.raw_data

        return channel_data


    def __str__(self):
        """
        Reimplemented string method that provides some basic info about the
        EK80 class instance's contents.

        Returns: Message to print when calling print method on EK80 class
        instance object.
        """

        # Print the class and address.
        msg = str(self.__class__) + " at " + str(hex(id(self))) + "\n"




        # Print some more info about the EK60 instance.
        if self.channel_ids:
            n_channels = len(self.channel_ids)
            if n_channels > 1:
                msg = msg + ("    EK80 object contains data from " + str(
                    n_channels) + " channels:\n")
            else:
                msg = msg + ("    EK80 object contains data from 1 channel:\n")

            for channel_id in self.channel_ids:
                for raw in self.raw_data[channel_id]:
                    msg = msg + ("        " + channel_id + " :: " + raw.data_type + " " + str(raw.shape) + "\n")
            msg = msg + ("    data start time: " + str(self.start_time) + "\n")
            msg = msg + ("      data end time: " + str(self.end_time) + "\n")
            msg = msg + ("    number of pings: " + str(self.end_ping -
                                                       self.start_ping + 1) + "\n")

        else:
            msg = msg + ("  EK80 object contains no data\n")

        return msg


class raw_data(ping_data):
    """
    the raw_data class contains a single channel's data extracted from a
    Kongsberg EK80 raw.
    """

    # Define some instrument specific constants.

    # Define constants used to specify the target resampling interval for the
    # power and angle conversion functions.  These values represent the
    # standard sampling intervals for EK60 hardware when operated with the
    # ER60 software as well as ES60/70 systems and the ME70(?).
    RESAMPLE_SHORTEST = 0
    RESAMPLE_16   = 0.000016
    RESAMPLE_32  = 0.000032
    RESAMPLE_64  = 0.000064
    RESAMPLE_128  = 0.000128
    RESAMPLE_256 = 0.000256
    RESAMPLE_512 = 0.000512
    RESAMPLE_1024 = 0.001024
    RESAMPLE_2048 = 0.002048
    RESAMPLE_LONGEST = 1

    # Create a constant to convert indexed power to power.
    INDEX2POWER = (10.0 * np.log10(2.0) / 256.0)

    # Create a constant to convert from indexed angles to electrical angles.
    INDEX2ELEC = 180.0 / 128.0


    def __init__(self, channel_id, n_pings=500, n_samples=-1,
                 rolling=False, store_power=True,
                 store_angles=True, store_complex=True,
                 max_sample_number=None):
        """Creates a new, empty raw_data object.

        The raw_data class stores raw echosounder data from a single channel
        recorded using the Kongsberg EK80 application. This class supports
        both EK60 GPTs running on EK80 software as well as EK80 WBT's operated
        using the EK80 software.

        NOTE: power is *always* stored in log form. If you manipulate power
              values directly, make sure they are stored in log form.

        The data arrays are not created upon instantiation. They will be created
        when the first ping is appended using the append_ping method.

        If rolling is True, and both the n_pings and n_samples arguments are
        provided, arrays of size (n_pings, n_samples) are created upon
        instantiation. Otherwise, the data arrays are created


        Args:
            channel_id (str): The channel ID of channel whose data are stored
                in this raw_data instance.
            n_pings (int): Sets the fixed "width" of the arrays for rolling
                arrays and if the object is not using rolling arrays it defines
                the "width" of the allocation chunks when appending data.
            n_samples (int): Sets the number of samples (rows) of the
                arrays. Default value is -1 samples which means the arrays
                will automatically resize to hold all of the sample data.
            rolling (bool): True = arrays have fixed sizes of n_pings set when
                the class is instantiated. When the n_pings + 1 ping is added
                the array is rolled left, dropping oldest ping and adding newest.
            store_power (bool): Boolean to control whether power data are
                stored in this raw_data object.
            store_angles (bool): Boolean to control whether angle data are
                stored in this raw_data object.
            store_complex (bool): Boolean to control whether complex data are
                stored in this raw_data object.
            max_sample_number (int): Integer specifying the maximum number of
                samples that will be stored in this instance's data arrays.
        """
        super(raw_data, self).__init__()

        # Specify if data array size is fixed and the array data is rolled left
        # if the array fills up (True) or if the arrays are expanded when
        # necessary to hold additional data (False).
        self.rolling_array = bool(rolling)

        # If rolling is set, ensure we have been passed n_samples
        if self.rolling_array and n_samples < 1:
            raise ValueError('The n_samples argument must be defined and ' +
                    'greater than 0 when rolling == True.')

        # The channel ID is the unique identifier of the channel stored in
        # the object.
        self.channel_id = channel_id

        # Specify the horizontal size (columns) of the array allocation size.
        self.chunk_width = n_pings

        # Keep note if we should store the power, angle, or complex data.
        self.store_power = bool(store_power)
        self.store_angles = bool(store_angles)
        self.store_complex = bool(store_complex)

        # Max_sample_number can be set to an integer specifying the maximum
        # number of samples that will be stored in the sample data arrays.
        # Samples beyond this will be discarded.
        self.max_sample_number = max_sample_number

        # data_type will be set to a string describing the type of sample data
        # stored. This value is an empty string until the first raw datagram
        # is added. At that point the data_type is set. A raw_data object can
        # only store 1 type of data. Thedata_type are:
        #
        #   power - contains power data
        #   power/angle - contains power and angle data
        #   complex - contains complex data
        self.data_type = ''

        # transceiver_type stores the hardware identifier of the transceiver
        # used to collect the data. This is set when reading the file.
        # I believe that the types are:
        #
        #   GPT - Ex60 General Purpose Transceiver
        #   WBT - Ex80 Wide Band Transceiver
        #   WBT MINI -
        #   WBT TUBE -
        #   WBT HP -
        #   WBT LF -
        #   WBAT - Wide Band Autonomous Transceiver
        #   SBT
        self.transceiver_type = None

        # Data_attributes is an internal list that contains the names of all
        # of the class's "data" properties. The echolab2 package uses this
        # attribute to generalize various functions that manipulate these
        # data.  Here we *extend* the list that is defined in the parent class.
        self._data_attributes += ['configuration',
                                  'environment',
                                  'filters',
                                  'channel_mode',
                                  'pulse_form',
                                  'frequency',
                                  'pulse_duration',
                                  'sample_interval',
                                  'slope',
                                  'transmit_power',
                                  'sample_count',
                                  'sample_offset']


    def empty_like(self, n_pings):
        """Returns raw_data object with data arrays filled with NaNs.

        The raw_data object has the same general characteristics of "this"
        object, but with data arrays filled with NaNs.

        Args:
            n_pings (int): Set n_pings to an integer specifying the number of
                pings in the new object. The vertical axis (both number of
                samples and depth/range values) will be the same as this object.
        """

        # Create an instance of echolab2.EK80.raw_data and set the same basic
        # properties as this object.  Return the empty processed_data object.
        empty_obj = raw_data(self.channel_id, n_pings=n_pings,
                n_samples=self.n_samples, rolling=self.rolling_array,
                chunk_width=n_pings, store_power=self.store_power,
                store_angles=self.store_angles, store_complex=self.store_complex,
                max_sample_number=self.max_sample_number)

        return self._like(empty_obj, n_pings, np.nan, empty_times=True)


    def insert(self, obj_to_insert, ping_number=None, ping_time=None,
               insert_after=True, index_array=None):
        """Inserts data from one raw_data object into another. Pings within the
        obj_to_insert can be inserted as a block, or they can be inserted
        individually.

        Args:
            obj_to_insert: An instance of echolab2.EK80.raw_data that contains
                the data to insert.If obj_to_insert is None, pings are inserted
                with all fields set to NaN.

            ping_number, ping_time, and index_array are exclusive. Only set 1.

            ping_number (int): Set to an integer indicating the ping number where the
                data should be inserted.
            ping_time (datetime):Set to an integer indicating the ping number where the
                data should be inserted.
            index_array (array):Set to a numpy array that is the same length
                as the raw_data object you're inserting where each element is
                an index into the array you're inserting into which maps each
                inserted ping into the raw_data object.
            insert_after (bool): Set to True to insert data after the ping/time/index
                specified.

        """
        # Determine how many pings we're inserting.
        if index_array is None:
            in_idx = self.get_indices(start_time=ping_time, end_time=ping_time,
                    start_ping=ping_number, end_ping=ping_number)[0]
            n_inserting = self.n_pings - in_idx
        else:
            n_inserting = index_array.shape[0]

        # When obj_to_insert is None, we automatically create a matching
        # object that contains no data (all NaNs).
        if obj_to_insert is None:
            obj_to_insert = self.empty_like(n_inserting)

        # Check that the data types are the same.
        if not isinstance(obj_to_insert, raw_data):
            raise TypeError('The object you are inserting must be an instance '
                    + 'of echolab2.EK80.raw_data')

        # We are now coexisting in harmony - call parent's insert.
        super(raw_data, self).insert(obj_to_insert, ping_number=ping_number,
                ping_time=ping_time, insert_after=insert_after,
                index_array=index_array)


    def append_ping(self, sample_datagram, config_params, environment_datagram,
            tx_parms, filters, start_sample=None, end_sample=None):
        """Adds a "pings" worth of data to the object.

        This method extracts data from the provided sample_datagram dict and
        inserts it into the data arrays. Managing the data array sizes is the
        bulk of what this method does:

        If the raw_data.rolling_array attribute is false, columns are added to
        the data arrays as needed. To reduce overhead, the arrays are extended in
        chunks, not on a ping by ping basis. If the recording range or the pulse
        length changes requiring additional rows to be added, the data arrays will be
        resized to accomodate the maximum number of samples being stored. Existing
        samples are padded with NaNs as required. This vertical resize does not
        occur in chunks and the data are copied each time samples are added.
        This can have significant performance impacts in very specific cases.

        If raw_data.rolling_array is true, the data arrays are not resized but
        the data within the arrays is "rolled" or shifted left and the column at
        index 0 is moved to index n_pings - 1. Additional samples are discarded
        and pings with fewer samples are padded with NaNs as required.

        This method is typically only called by the EK80 class when reading a raw file.

        Args:
            sample_datagram (dict): The dictionary containing the parsed sample datagram.
            config_datagram (dict): The dictionary containing the parsed XML configuration
                                    datagram that goes with this sample data.
            environment_datagram (dict): A dictionary containing the latest parsed XML
                                         environment datagram.
            tx_parms (dict): The dictionary containing the most recent XML parameter
                             datagram for this channel.
            filters (dict): A dictionary containing this channels filter coefficients
                            used by the EK80 to filter the received signal.
            start_sample (int):
            end_sample (int):
        """

        # Set some defaults
        complex_samps = -1
        power_samps = -1
        angle_samps = -1
        n_complex = 0
        max_data_samples = []

        # The contents of the first ping appended to a raw_data object defines
        # thedata_type and determines how the data arrays will be created. Also,
        # since a raw_data object can only store onedata_type, we disable saving
        # of the other types.
        if self.n_pings == -1:

            # Set defaults
            create_complex = False
            create_power = False
            create_angles = False

            #  Determine what kind of data we've been given - complex or power/angle
            if sample_datagram['complex'] is not None:
                # This is a complex datagram. Store complex data only
                create_complex = True
                complex_samps = sample_datagram['complex'].shape[0]
                n_complex = sample_datagram['complex'].shape[1]
                self.store_power = False
                self.store_angles = False
                self.data_type = 'complex'
                #  for complex data, we set the sample array type to complex64
                self.sample_dtype = np.complex64

            else:
                # This must be a power, angle, or power/angle datagram
                # Check if either or both are provided
                if  sample_datagram['power'] is not None:
                    create_power = True
                    self.store_complex = False
                    power_samps = sample_datagram['power'].shape[0]
                    self.data_type = 'power'

                if sample_datagram['angle'] is not None:
                    create_angles = True
                    self.store_complex = False
                    angle_samps = sample_datagram['angle'].shape[0]
                    if create_power:
                        self.data_type = 'power/angle'
                    else:
                        self.store_power = False
                        self.data_type = 'angle'

                # At this point if we're power, we're not storing angle data
                if self.data_type == 'power':
                    self.store_angles = False

            #  determine the initial number of samples in our arrays
            if self.max_sample_number:
                n_samples = self.max_sample_number
            else:
                n_samples = max([angle_samps, power_samps, complex_samps])

            #  set the initial sample offset
            self.sample_offset = sample_datagram['offset']

            #  Initialize the data arrays
            self._create_arrays(self.chunk_width, n_samples, initialize=False,
                    create_power=create_power, create_angles=create_angles,
                    create_complex=create_complex, n_complex=n_complex)

            # Initialize the ping counter to indicate that our data arrays
            # have been allocated.
            self.n_pings  = 0

        #  determine the number of samples in this datagram as well
        # as the number of samples in our data array(s).
        if self.store_angles:
            angle_samps = sample_datagram['angle'].shape[0]
            max_data_samples.append(self.angles_alongship_e.shape[1])
            max_data_samples.append(self.angles_athwartship_e.shape[1])
        if self.store_power:
            power_samps = sample_datagram['power'].shape[0]
            max_data_samples.append(self.power.shape[1])
        if self.store_complex:
            complex_samps = sample_datagram['complex'].shape[0]
            n_complex = sample_datagram['complex'].shape[1]
            max_data_samples.append(self.complex.shape[1])

            # Check to ensure the number of sectors hasn't changed.
            # I am assuming the channel ID will change because the
            # transducer would have to change for the sectors to change.
            # If I'm wrong, we need to track this in the EK80 object and
            # create a new raw_data object for data with different n_complex
            #  values.
            if self.complex.shape[2] != n_complex:
                raise ValueError("The number of complex values changed after object " +
                        "creation. Why didn't the channel ID change??")

        max_data_samples = max(max_data_samples)
        max_new_samples = max([power_samps, angle_samps, complex_samps])

        # Check if we need to truncate the sample data.
        if self.max_sample_number and (max_new_samples > self.max_sample_number):
            max_new_samples = self.max_sample_number
            if self.store_angles:
                sample_datagram['angle'] = \
                        sample_datagram['angle'][0:self.max_sample_number]
            if self.store_power:
                sample_datagram['power'] = \
                        sample_datagram['power'][0:self.max_sample_number]
            if self.store_complex:
                sample_datagram['complex'] = \
                        sample_datagram['complex'][0:self.max_sample_number:]

        # Create 2 variables to store our current array size.
        ping_dims = self.ping_time.size
        sample_dims = max_data_samples

        # Check if we need to re-size or roll our data arrays.
        if self.rolling_array == False:
            # Check if we need to resize our data arrays.
            ping_resize = False
            sample_resize = False

            # Check the ping dimension.
            if self.n_pings == ping_dims:
                # Need to resize the ping dimension.
                ping_resize = True
                # Calculate the new ping dimension.
                ping_dims = ping_dims + self.chunk_width

            # Check the samples dimension.
            if max_new_samples > max_data_samples:
                # Need to resize the samples dimension.
                sample_resize = True
                # Calculate the new samples dimension.
                sample_dims = max_new_samples

            # Determine if we resize.
            if ping_resize or sample_resize:
                self.resize(ping_dims, sample_dims)

            # Get an index into the data arrays for this ping and increment
            # our ping counter.
            this_ping = self.n_pings
            self.n_pings += 1

        else:
            # Check if we need to roll.
            if self.n_pings == ping_dims - 1:
                # When a rolling array is "filled" we stop incrementing the
                # ping counter and repeatedly append pings to the last ping
                # index in the array.
                this_ping = self.n_pings

                # Roll our array 1 ping.
                self._roll_arrays(1)

        # Update the channel configuration dict's end_* values
        config_params['end_ping'] = self.n_pings
        config_params['end_time'] = sample_datagram['timestamp']

        # Insert the config, environment, and filter object references for this ping.
        self.configuration[this_ping] = config_params
        self.environment[this_ping] = environment_datagram
        self.filters[this_ping] = filters

        # Now insert the data into our numpy arrays.
        self.ping_time[this_ping] = sample_datagram['timestamp']
        self.channel_mode[this_ping] = tx_parms['channel_mode']
        self.pulse_form[this_ping] = tx_parms['pulse_form']
        self.frequency[this_ping] = tx_parms['frequency']
        self.pulse_duration[this_ping] = tx_parms['pulse_duration']
        self.sample_interval[this_ping] = tx_parms['sample_interval']
        self.slope[this_ping] = tx_parms['slope']
        self.transmit_power[this_ping] = tx_parms['transmit_power']

        # Update sample count and sample offset values
        if start_sample:
            self.sample_offset[this_ping] = start_sample + sample_datagram['offset']

            if end_sample:
                self.sample_count[this_ping] = end_sample - start_sample + 1
            else:
                self.sample_count[this_ping] = sample_datagram['count'] - \
                                               start_sample
        else:
            self.sample_offset[this_ping] = sample_datagram['offset']
            start_sample = 0
            if end_sample:
                self.sample_count[this_ping] = end_sample + 1
            else:
                self.sample_count[this_ping] = sample_datagram['count']
                end_sample = sample_datagram['count']

        # Now store the "sample" data.

        # Check if we need to store complex data.
        if self.store_complex:

            # Get the subset of samples we're storing.
            complex = sample_datagram['complex'][start_sample:self.sample_count[
                this_ping],:]

            # Check if we need to pad or trim our sample data.
            sample_pad = sample_dims - complex.shape[0]
            if sample_pad > 0:
                # The data array has more samples than this datagram - we
                # need to pad the datagram.
                self.complex[this_ping,:,:] = np.pad(complex,((0,sample_pad),(0,0)),
                        'constant', constant_values=np.nan)
            elif sample_pad < 0:
                # The data array has fewer samples than this datagram - we
                # need to trim the datagram.
                self.complex[this_ping,:,:] = complex[0:sample_pad,:]
            else:
                # The array has the same number of samples.
                self.complex[this_ping,:,:] = complex

        # Check if we need to store power data.
        if self.store_power:

            # Get the subset of samples we're storing.
            power = sample_datagram['power'][start_sample:self.sample_count[this_ping]]

            # Convert the indexed power data to power dB.
            power = power.astype(self.sample_dtype) * self.INDEX2POWER

            # Check if we need to pad or trim our sample data.
            sample_pad = sample_dims - power.shape[0]
            if sample_pad > 0:
                # The data array has more samples than this datagram - we
                # need to pad the datagram.
                self.power[this_ping,:] = np.pad(power,(0,sample_pad),
                        'constant', constant_values=np.nan)
            elif sample_pad < 0:
                # The data array has fewer samples than this datagram - we
                # need to trim the datagram.
                self.power[this_ping,:] = power[0:sample_pad]
            else:
                # The array has the same number of samples.
                self.power[this_ping,:] = power

        # Check if we need to store angle data.
        if self.store_angles:

            # Convert from indexed to electrical angles.
            alongship_e = sample_datagram['angle'] \
                [start_sample:self.sample_count[this_ping], 1] \
                .astype(self.sample_dtype) * self.INDEX2ELEC
            athwartship_e = sample_datagram['angle'] \
                [start_sample:self.sample_count[this_ping], 0] \
                .astype(self.sample_dtype) * self.INDEX2ELEC

            # Check if we need to pad or trim our sample data.
            sample_pad = sample_dims - athwartship_e.shape[0]
            if sample_pad > 0:
                # The data array has more samples than this datagram - we
                # need to pad the datagram
                self.angles_alongship_e[this_ping,:] = np.pad(alongship_e,
                        (0,sample_pad), 'constant', constant_values=np.nan)
                self.angles_athwartship_e[this_ping,:] = np.pad(
                    athwartship_e,(0,sample_pad), 'constant', constant_values=np.nan)
            elif sample_pad < 0:
                # The data array has fewer samples than this datagram - we
                # need to trim the datagram.
                self.angles_alongship_e[this_ping,:] = alongship_e[0:sample_pad]
                self.angles_athwartship_e[this_ping,:] = athwartship_e[0:sample_pad]
            else:
                # The array has the same number of samples.
                self.angles_alongship_e[this_ping,:] = alongship_e
                self.angles_athwartship_e[this_ping,:] = athwartship_e


    def get_calibration(self, **kwargs):
        """Returns a calibration object populated from the data contained in this
        raw_data object.

        """

        cal_obj = ek80_calibration(**kwargs)
        cal_obj.from_raw_data(self)

        return cal_obj


    def get_power(self, **kwargs):
        """Returns a processed data object that contains the power data.

        This method performs all of the required transformations to place the
        raw power data into a rectangular array where all samples share the same
        thickness and are correctly arranged relative to each other.

        This process happens in 3 steps:

                Data are resampled so all samples have the same thickness.
                Data are shifted vertically to account for the sample offsets.
                Data are then regridded to a fixed time, range grid.

        Each step is performed only when required. Calls to this method will
        return much faster if the raw data share the same sample thickness,
        offset and sound speed.

        If calibration is set to an instance of EK80.calibration the
        values in that object (if set) will be used when performing the
        transformations required to return the results. If the required
        parameters are not set in the calibration object or if no object is
        provided, this method will extract these parameters from the raw file
        data.

        Args:
            **kwargs (dict): A keyworded argument list.

        Returns:
            The processed_data object, p_data.
        """

        # Call the _get_sample_data method requesting the appropriate sample attribute.
        if hasattr(self, 'power'):
            p_data, return_indices = self._get_sample_data('power', **kwargs)
        elif hasattr(self, 'complex'):
            raise NotImplementedError('Conversion of complex data to power ' +
                    'is not implemented at this time.')
        else:
            raise AttributeError('Raw data object does not contain power or ' +
                    'complex data required to return power.')

        # Set the data type.
        p_data.data_type = 'power'

        # Set the is_log attribute and return it.
        p_data.is_log = True

        return p_data


    def _get_power(self, **kwargs):
        """Returns a processed data object that contains the power data and
        an index array.

        This method is identical to get_power except that it also returns an
        index array that maps the pings in the processed_data object to the
        same pings in the "this" object. This is used internally.

        Args:
            **kwargs (dict): A keyworded argument list.

        Returns:
            The processed data object, p_data, and an index array of pings,
            return_indices.
        """

        # Call the _get_sample_data method requesting the appropriate sample attribute.
        if hasattr(self, 'power'):
            p_data, return_indices = self._get_sample_data('power', **kwargs)
        elif hasattr(self, 'complex'):
            raise NotImplementedError('Conversion of complex data to power ' +
                    'is not implemented at this time.')
        else:
            raise AttributeError('Raw data object does not contain power or ' +
                    'complex data required to return power.')

        # Set the data type.
        p_data.data_type = 'power'

        # Set the is_log attribute and return it.
        p_data.is_log = True

        return p_data, return_indices


    def get_sv(self, **kwargs):
        """Gets sv data.

        This is a convenience method which simply calls get_Sv and forces
        the linear keyword to True.

        Args:
            **kwargs (dict): A keyworded argument list.

        Returns:
            A processed data object containing sv.
        """

        # Remove the linear keyword.
        kwargs.pop('linear', None)

        # Call get_Sp forcing linear to True.
        return self.get_Sv(linear=True, **kwargs)


    def get_Sv(self, calibration=None, linear=False, tvg_correction=True,
               return_depth=False, **kwargs):
        """Gets Sv data

        The value passed to cal_parameters is a calibration parameters object.
        If cal_parameters == None, the calibration parameters will be extracted
        from the corresponding fields in the raw_data object.

        Sv is calculated as follows:

            Sv = recvPower + 20 log10(Range) + (2 *  alpha * Range) - (10 * ...
                log10((xmitPower * (10^(gain/10))^2 * lambda^2 * ...
                c * tau * 10^(psi/10)) / (32 * pi^2)) - (2 * SaCorrection)
        Args:
            calibration (float):
            linear (bool): Set to True if getting "sv" data
            tvg_correction:
            return_depth (float):
            **kwargs (dict): A keyworded argument list.

        Returns:
            A processed_data object, p_data, containing Sv (or sv if linear is
            True).
        """

        # Get the power data - this step also resamples and arranges the raw data.
        p_data, return_indices = self._get_power(calibration=calibration, **kwargs)

        # Set the data type and is_log attribute.
        if linear:
            attribute_name = 'sv'
            p_data.is_log = False

        else:
            attribute_name = 'Sv'
            p_data.is_log = True
        p_data.data_type = attribute_name

        # Convert power to Sv/sv.
        sv_data = self._convert_power(p_data, calibration, attribute_name,
                linear, return_indices, tvg_correction)

        # Set the data attribute in the processed_data object.
        p_data.data = sv_data

        # Check if we need to convert to depth
        if return_depth:
            p_data.to_depth(calibration)

        return p_data


    def get_sp(self, **kwargs):
        """Gets sp data.

        This is a convenience method which simply calls get_Sp and forces
        the linear keyword to True.

        Args:
            **kwargs (dict): A keyworded argument list.

        Returns:
            returns a processed_data object containing sp
        """

        # Remove the linear keyword.
        kwargs.pop('linear', None)

        # Call get_Sp, forcing linear to True.
        return self.get_Sp(linear=True, **kwargs)


    def get_Sp(self,  calibration=None, linear=False, tvg_correction=False,
            return_depth=False, **kwargs):
        """Gets Sp data.

        Sp is calculated as follows:

             Sp = recvPower + 40 * log10(Range) + (2 *  alpha * Range) - (10
             * ... log10((xmitPower * (10^(gain/10))^2 * lambda^2) / (16 *
             pi^2)))

        By default, TVG range correction is not applied to the data. This
        results in output that is consistent with the Simrad "P" telegram and TS
        data exported from Echoview version 4.3 and later (prior versions
        applied the correction by default).

        If you intend to perform single target detections you must apply the
        TVG range correction at some point in your process. This can be done by
        either setting the tvgCorrection keyword of this function or it can be
        done as part of your single target detection routine.

        Args:
            calibration (calibration object): The data calibration object where
                calibration data will be retrieved.
            linear (bool): Set to True if getting Sp data.
            tvg_correction (bool): Set to True to apply a correction to the
                range of 2 * sample thickness.
            return_depth (bool): If true, return the vertical axis of the
                data as depth.  Otherwise, return as range.
            **kwargs

        Returns:
            A processed_data object, p_data, containing Sp (or sp if linear is
            True).
        """

        # Get the power data - this step also resamples and arranges the raw data.
        p_data, return_indices = self._get_power(calibration=calibration, **kwargs)

        # Set the data type.
        if linear:
            attribute_name = 'sp'
            p_data.is_log = False
        else:
            attribute_name = 'Sp'
            p_data.is_log = True
        p_data.data_type = attribute_name

        # Convert
        sp_data = self._convert_power(p_data, calibration, attribute_name,
                linear, return_indices, tvg_correction)

        # Set the data attribute in the processed_data object.
        p_data.data = sp_data

        # Check if we need to convert to depth or heave correct.
        if return_depth:
            p_data.to_depth(calibration)

        return p_data


    def get_bottom(self, calibration=None, return_indices=None,
            return_depth=False, **kwargs):
        """Gets a echolab2 line object containing the sounder detected bottom
        depths.

        The sounder detected bottom depths are computed using the sound speed
        setting at the time of recording. If you are applying a different sound
        speed setting via the calibration argument when getting the converted
        sample data, you must also pass the same calibration object to this method
        to ensure that the sounder detected bottom depths align with your sample
        data.

        Args:
            calibration (calibration object): The data calibration object where
                calibration data will be retrieved.
            return_indices (array): A numpy array
            return_depth (bool): If true, return the vertical axis of the
                data as depth.  Otherwise, return as range.
            **kwargs

        Raises:
            ValueError: The return indices exceed the number of pings in
                the raw data object

        Returns:
            A line object, bottom_line, containing the sounder detected bottom
            depths.
        """

        # Check if the user supplied an explicit list of indices to return.
        if isinstance(return_indices, np.ndarray):
            if max(return_indices) > self.ping_time.shape[0]:
                raise ValueError("One or more of the return indices provided " +
                        "exceeds the number of pings in the raw_data object")
        else:
            # Get an array of index values to return.
            return_indices = self.get_indices(**kwargs)

        # Check if user provided a cal object
        if calibration is None:
            # No - create an empty one - all cal values will come from the raw data
            calibration = ek80_calibration()

        # Extract the recorded sound velocity.
        sv_recorded = self.sound_velocity[return_indices]

        # Get the calibration params required for detected depth conversion.
        cal_parms = {'sound_velocity':None,
                     'transducer_depth':None}

        # Next, iterate through the dict, calling the method to extract the
        # values for each parameter.
        for key in cal_parms:
            cal_parms[key] = calibration.get_calibration_param(self, key,
                    return_indices)

        # Check if we have to adjust the depth due to a change in sound speed.
        if np.all(np.isclose(sv_recorded, cal_parms['sound_velocity'])):
            converted_depths = self.detected_bottom[return_indices]
        else:
            cf = sv_recorded / cal_parms['sound_velocity']
            converted_depths = cf * self.detected_bottom[return_indices]

        # Check if we're returning range by subtracting a transducer offset.
        if return_depth == False:
            # Data is recorded as depth - convert to range.
            converted_depths -= cal_parms['transducer_depth'][return_indices]

        # Create a line object to return with our adjusted data.
        bottom_line = line.Line(ping_time=self.ping_time[return_indices],
                data=converted_depths)

        return bottom_line


    def get_physical_angles(self, calibration=None, **kwargs):
        """Gets the alongship and athwartship angle data.

        Args:
            calibration (calibration object): The data calibration object where
                calibration data will be retrieved.
            **kwargs

        Returns:
            Processed data objects with alongship and athwartship angle data.
        """

        # Check if user provided a cal object
        if calibration is None:
            # No - create an empty one - all cal values will come from the raw data
            calibration = ek80_calibration()

        # Get the electrical angles.
        alongship, athwartship, return_indices = \
                self._get_electrical_angles(calibration=calibration, **kwargs)

        # Get the calibration params required for angle conversion.
        cal_parms = {'angle_sensitivity_alongship':None,
                     'angle_sensitivity_athwartship':None,
                     'angle_offset_alongship':None,
                     'angle_offset_athwartship':None}

        # Next, iterate through the dict, calling the method to extract the
        # values for each parameter.
        for key in cal_parms:
            cal_parms[key] = calibration.get_calibration_param(self, key,
                    return_indices)

        # Compute the physical angles.
        alongship.data[:] = (alongship.data /
                cal_parms['angle_sensitivity_alongship'][:, np.newaxis])
        alongship.data -= cal_parms['angle_offset_alongship'][:, np.newaxis]
        athwartship.data[:] = (athwartship.data /
                cal_parms['angle_sensitivity_athwartship'][:, np.newaxis])
        athwartship.data -= cal_parms['angle_offset_athwartship'][:,
                               np.newaxis]

        # Set the data types.
        alongship.data_type = 'angles_alongship'
        athwartship.data_type = 'angles_athwartship'

        # We do not need to convert to depth here since the electrical_angle
        # data will already have been converted to depth if requested.

        return alongship, athwartship


    def get_electrical_angles(self, return_depth=False, calibration=None, **kwargs):
        """Gets unconverted angles_alongship_e and angles_athwartship_e data.

        Args:
            return_depth (bool): If true, return the vertical axis of the
                data as depth.  Otherwise, return as range.
            calibration (calibration object): The data calibration object where
                calibration data will be retrieved.
            **kwargs

        Returns:
            Two processed data objects containing the unconverted
            angles_alongship_e and angles_athwartship_e data.
        """

        # Call the _get_sample_data method requesting the 'angles_alongship_e'
        # sample attribute. The method will return a reference to a newly created
        # processed_data object.
        alongship, return_indices = self._get_sample_data('angles_alongship_e',
                **kwargs)

        # Repeat for the athwartship data.
        athwartship, return_indices = self._get_sample_data('angles_athwartship_e',
                **kwargs)

        # Set the data type.
        alongship.data_type = 'angles_alongship_e'
        athwartship.data_type = 'angles_athwartship_e'

        # Covert to depth
        if return_depth:
            alongship.to_depth(calibration)
            athwartship.to_depth(calibration)

        return alongship, athwartship


    def _get_electrical_angles(self, return_depth=False, calibration=None,
            **kwargs):
        """Retrieves unconverted angles_alongship_e and angles_athwartship_e
        data and creates an index array mapping pings.

        _get_electrical_angles is identical to get_electrical_angles except
        that it also returns an index array that maps the pings in the
        processed_data object to the same pings in the "this" object. This is
        used internally.

        Args:
            return_depth (bool): If true, return the vertical axis of the
                data as depth.  Otherwise, return as range.
            calibration (calibration object): The data calibration object where
                calibration data will be retrieved.
            **kwargs

        Returns:
            Two processed data objects containing the unconverted
            angles_alongship_e and angles_athwartship_e data and an index array
            mapping pings to this object.
        """

        # Call the _get_sample_data method requesting the 'angles_alongship_e'
        # sample attribute. The method will return a reference to a newly created
        # processed_data object.
        if hasattr(self, 'angles_alongship_e') or hasattr(self, 'angles_athwartship_e'):
            if hasattr(self, 'angles_alongship_e'):
                alongship, return_indices = self._get_sample_data('angles_alongship_e',
                        **kwargs)
            else:
                raise AttributeError('Raw data object does not contain the ' +
                        'angles_alongship_e attribute required to return angle data.')

            # use the already computed return_indices from the first
            # call to _get_sample_data to get the athwartship data
            if hasattr(self, 'angles_athwartship_e'):
                kwargs.pop('return_indices', None)
                athwartship, ri = self._get_sample_data('angles_athwartship_e',
                        return_indices=return_indices, **kwargs)
            else:
                raise AttributeError('Raw data object does not contain the ' +
                        'angles_athwartship_e attribute required to return angle data.')

        elif hasattr(self, 'complex'):
            raise NotImplementedError('Conversion of complex data to angle data ' +
                    'is not implemented at this time.')

        else:
            # We don't have complex nor electrical angle data required so
            # we can't do anything.
            raise AttributeError('Raw data object does not contain the raw ' +
                        'data required to return angle data.')


        # Set the data type.
        alongship.data_type = 'angles_alongship_e'
        athwartship.data_type = 'angles_athwartship_e'

        # Apply depth and/or heave correction
        if return_depth:
            alongship.to_depth(calibration)
            athwartship.to_depth(calibration)

        return alongship, athwartship, return_indices


    def _get_sample_data(self, property_name, calibration=None,
            resample_interval=RESAMPLE_SHORTEST, return_indices=None,
            **kwargs):
        """Retrieves sample data.

        This method returns a processed data object that contains the
        sample data from the property name provided. It performs all of the
        required transformations to place the raw data into a rectangular
        array where all samples in all pings share the same thickness and are
        correctly arranged relative to each other.

        This process happens in 3 steps:

                Data are resampled so all samples have the same thickness.
                Data are shifted vertically to account for the sample offsets.
                Data are then regridded to a fixed time, range grid.

        Each step is performed only when required. Calls to this method will
        return much faster if the raw data share the same sample thickness,
        offset and sound speed.

        If calibration is set to an instance of an EK80.calibration object
        the values in that object (if set) will be used when performing the
        transformations required to return the results. If the required
        parameters are not set in the calibration object or if no object is
        provided, this method will extract these parameters from the raw data.

        Args:
            property_name (str): The attribute name of the sample data
                to be returned. For the EK80 the sample data attributes
                are 'complex', 'power', 'angles_alongship_e', and
                'angles_athwartship_e' and the available attributes will
                depend on how the data were collected and stored.

            calibration (EK80.calibration object): The calibration object where
                calibration data will be retrieved. If this is set to None,
                calibration data will be directly extracted from the raw

            resample_interval (float): The echosounder sampling interval used to
                define the vertical position of the samples. If data was collected
                with a different sampling interval it will be resampled to
                the specified interval. The default behavior is to resample
                to the shortest sampling interval in the data. This value has
                no effect when all data share the same sampling interval.

            return_indices (array): A numpy array of indices to return.

        Raises:
            ValueError: Return indices exceeds the number of pings.
            AttributeError: The attribute name doesn't exist.

        Returns:
            The processed data object containing the sample data.
        """

        def get_range_vector(num_samples, sample_interval, sound_speed,
                             sample_offset):
            """
            get_range_vector returns a NON-CORRECTED range vector.
            """
            # Calculate the thickness of samples with this sound speed.
            thickness = sample_interval * sound_speed / 2.0
            # Calculate the range vector.
            range = (np.arange(0, num_samples) + sample_offset) * thickness

            return range

        # Check if the user supplied an explicit list of indices to return.
        if isinstance(return_indices, np.ndarray):
            if max(return_indices) > self.ping_time.shape[0]:
                raise ValueError("One or more of the return indices provided "
                        "exceeds the " + "number of pings in the " + "raw_data object")
        else:
            # Get an array of index values to return.
            return_indices = self.get_indices(**kwargs)

        # Check if user provided a cal object
        if calibration is None:
            # No - create an empty one - all cal values will come from the raw data
            calibration = ek80_calibration()

        # Create the processed_data object we will return.
        p_data = processed_data(self.channel_id, self.frequency[0], None)

        # Populate it with time and ping number.
        p_data.ping_time = self.ping_time[return_indices].copy()

        # Get a reference to the data we're operating on.
        if hasattr(self, property_name):
            data = getattr(self, property_name)
        else:
            raise AttributeError("The attribute name " + property_name +
                    " does not exist.")

        # Populate the calibration parameters required for this method.
        # First, create a dict with key names that match the attributes names
        # of the calibration parameters we require for this method.
        cal_parms = {'sample_interval':None,
                     'sound_speed':None,
                     'sample_offset':None,
                     'transducer_mounting':None,
                     'drop_keel_offset': None,
                     'transducer_offset_z': None,
                     'water_level_draft': None}

        # Next, iterate through the dictionary calling the method to extract
        # the values for each parameter.
        for key in cal_parms:
            cal_parms[key] = calibration.get_parameter(self, key,
                    return_indices)

        # Check if we have multiple sample offset values and get the minimum.
        unique_sample_offsets = np.unique(
            cal_parms['sample_offset'][~np.isnan(cal_parms['sample_offset'])])
        min_sample_offset = min(unique_sample_offsets)

        # Check if we need to resample our sample data.
        unique_sample_interval = np.unique(
            cal_parms['sample_interval'][~np.isnan(cal_parms['sample_interval'])])
        if unique_sample_interval.shape[0] > 1:
            # There are at least 2 different sample intervals in the data.  We
            # must resample the data.  We'll deal with adjusting sample offsets
            # here too.
            (output, sample_interval) = self._vertical_resample(data[return_indices],
                    cal_parms['sample_interval'], unique_sample_interval, resample_interval,
                    cal_parms['sample_offset'], min_sample_offset,
                    is_power=property_name == 'power')
        else:
            # We don't have to resample, but check if we need to shift any
            # samples based on their sample offsets.
            if unique_sample_offsets.shape[0] > 1:
                # We have multiple sample offsets so we need to shift some of
                # the samples.
                output = self._vertical_shift(data[return_indices],
                        cal_parms['sample_offset'], unique_sample_offsets,
                        min_sample_offset)
            else:
                # The data all have the same sample intervals and sample
                # offsets.  Simply copy the data as is.
                output = data[return_indices].copy()

            # Get the sample interval value to use for range conversion below.
            sample_interval = unique_sample_interval[0]

        # Check if we have a fixed sound speed.
        unique_sound_velocity = np.unique(cal_parms['sound_speed'])
        if unique_sound_velocity.shape[0] > 1:
            # There are at least 2 different sound speeds in the data or
            # provided calibration data.  Interpolate all data to the most
            # common range (which is the most common sound speed).
            sound_velocity = None
            n = 0
            for speed in unique_sound_velocity:
                # Determine the sound speed with the most pings.
                if np.count_nonzero(cal_parms['sound_speed'] == speed) > n:
                   sound_velocity = speed

            # Calculate the target range.
            range = get_range_vector(output.shape[1], sample_interval,
                    sound_velocity, min_sample_offset)

            # Get an array of indexes in the output array to interpolate.
            pings_to_interp = np.where(cal_parms['sound_speed'] != sound_velocity)[0]

            # Iterate through this list of pings to change.  Interpolating each
            # ping.
            for ping in pings_to_interp:
                # Resample using the provided sound speed.
                resample_range = get_range_vector(output.shape[1], sample_interval,
                        cal_parms['sound_speed'][ping], min_sample_offset)
                output[ping,:] = np.interp(range, resample_range, output[ping, :])

        else:
            # We have a fixed sound speed and only need to calculate a single
            # range vector.
            sound_velocity = unique_sound_velocity[0]
            range = get_range_vector(output.shape[1], sample_interval,
                    sound_velocity, min_sample_offset)

        # Assign the results to the "data" processed_data object.
        p_data.add_data_attribute('data', output)

        # Calculate the sample thickness.
        sample_thickness = sample_interval * sound_velocity / 2.0

        # Now assign range, sound_velocity, sample thickness and offset to
        # the processed_data object.
        p_data.add_data_attribute('range', range)
        p_data.sound_velocity = sound_velocity
        p_data.sample_thickness = sample_thickness
        p_data.sample_offset = min_sample_offset
        p_data.sample_interval = sample_interval

        # Add the transducer draft attribute
        # First check if we apply the drop keel offset
        add_drop_keel = cal_parms['transducer_mounting'] == 'DropKeel'
        # Zero out offset where the mounting isn't DropKeel
        cal_parms['drop_keel_offset'][np.invert(add_drop_keel)] = 0.0
        # Compute the draft and add the attribute
        xdcr_draft = cal_parms['transducer_offset_z'] + cal_parms['drop_keel_offset']
        p_data.add_data_attribute('transducer_draft', xdcr_draft)

        # Return the processed_data object containing the requested data.
        return p_data, return_indices


    def _convert_power(
            self, power_data, calibration, convert_to, linear,
            return_indices, tvg_correction):
        """Converts power to Sv/sv/Sp/sp

        Args:
            power_data (processed_data): A processed_data object with the raw power
                data read from the file.
            calibration (calibration object): The data calibration object where
                calibration data will be retrieved.
            convert_to (str):  A string that specifies what to convert the
                power to.  Possible values are: Sv, sv, Sp, or sp.
            linear (bool):  Set to True to return linear values.
            return_indices (array): A numpy array of indices to return.
            tvg_correction (bool): Set to True to apply a correction to the
                range of 2 * sample thickness.

        Returns:
            An array with the converted data.
        """

        # Populate the calibration parameters required for this method.
        # First, create a dictionary with key names that match the attribute
        # names of the calibration parameters we require for this method.
        cal_parms = {'gain':None,
                     'transmit_power':None,
                     'equivalent_beam_angle':None,
                     'pulse_duration':None,
                     'absorption_coefficient':None,
                     'sa_correction':None,
                     'effective_pulse_duration':None}

        # Next, iterate through the dictionary, calling the method to extract
        # the values for each parameter.
        for key in cal_parms:
            cal_parms[key] = calibration.get_parameter(self, key,
                    return_indices)

        # Get sound_velocity from the power data since get_power might have
        # manipulated this value. Remember that we're operating on a
        # processed_data object so all pings share the same sound speed.
        cal_parms['sound_speed'] = np.empty((return_indices.shape[0]),
                dtype=self.sample_dtype)
        cal_parms['sound_speed'].fill(power_data.sound_velocity)

        # For EK60 hardware use pulse duration when computing gains
        # but for EK80 hardware use effectve pulse length.
        if self.transceiver_type == 'GPT':
            effective_pulse_duration = cal_parms['pulse_duration']
        else:
            effective_pulse_duration = cal_parms['effective_pulse_duration']

        # Calculate the system gains.
        wavelength = cal_parms['sound_speed'] / power_data.frequency
        if convert_to in ['sv','Sv']:
            gains = 10 * np.log10((cal_parms['transmit_power'] * (10**( cal_parms['gain'] / 10.0))**2 *
                    wavelength**2 * cal_parms['sound_speed'] * effective_pulse_duration *
                10**(cal_parms['equivalent_beam_angle']/10.0)) / (32 * np.pi**2))
        else:
            gains = 10 * np.log10((cal_parms['transmit_power'] * (10**(
                cal_parms['gain']/10.0))**2 * wavelength**2) / (16 * np.pi**2))

        # Get the range for TVG calculation.  The method used depends on the
        # hardware used to collect the data.
        c_range = np.empty(power_data.shape, dtype=power_data.sample_dtype)
        c_range [:,:] = power_data.range.copy()
        if tvg_correction:
            if self.transceiver_type == 'GPT':
                # For the Ex60 hardware, the corrected range is computed as:
                #   c_range = range - (2 * sample_thickness)
                c_range -= (2.0 * power_data.sample_thickness)
            else:
                # For the Ex80 WBT style hardware corrected range is computed as:
                #    c_range = range - (sound speed * pulse length / 4)
                c_range -= (power_data.sound_velocity * cal_parms['pulse_duration'] / 4.0)[:,np.newaxis]

            #  zero out negative ranges
            c_range[c_range < 0] = 0

        # Calculate time varied gain.
        tvg = c_range.copy()
        tvg[tvg < 1] = 1
        if convert_to in ['sv','Sv']:
            tvg = 20.0 * np.log10(tvg)
        else:
            tvg = 40.0 * np.log10(tvg)

        # Calculate absorption - our starting point.
        data = (2.0 * cal_parms['absorption_coefficient'])[:,np.newaxis] * c_range

        # Add in power and TVG.
        data += power_data.data + tvg

        # Subtract the applied gains.
        data -= gains[:, np.newaxis]

        # Apply sa correction for Sv/sv.
        if convert_to in ['sv','Sv']:
            data -= (2.0 * cal_parms['sa_correction'])[:, np.newaxis]

        # Check if we're returning linear or log values.
        if linear:
            # Convert to linear units (use [:] to operate in-place).
            data[:] = 10**(data / 10.0)

        # Return the result.
        return data


    def _to_depth(self, p_data, calibration, heave_correct, return_indices):
        """Converts data to depth.

        This is an internal method that converts data from range to depth and
        optionally applies heave correction.

        Args:
            p_data: A processed data object containing data to convert.
            calibration (calibration object): The calibration object where
                calibration data will be retrieved.
            heave_correct (bool): Set to True to apply heave correction.
            return_indices (array): A numpy array of indices to return.
        """

        # Populate the calibration parameters required for this method.
        # First, create a dictionary with key names that match the attribute
        # names of the calibration parameters we require for this method.
        cal_parms = {'transducer_depth':None,
                     'heave':None}



        # Next, iterate through the dictionary, calling the method to extract
        # the values for each parameter.
        for key in cal_parms:
            cal_parms[key] = calibration.get_parameter(self, key,
                    return_indices)

        # Check if we're applying heave correction and/or returning depth by
        # applying a transducer offset.
        if heave_correct:
            # Heave correction implies returning depth.  Determine the
            # vertical shift per-ping.
            vert_shift = cal_parms['heave'] + cal_parms['transducer_depth']
        else:
            # We're only converting to depth, determine the vertical shift
            # per-ping only applying the transducer draft.
            vert_shift = cal_parms['transducer_depth']

        # Now shift the pings.
        p_data.shift_pings(vert_shift, to_depth=True)





    def _create_arrays(self, n_pings, n_samples, initialize=False, create_power=False,
            create_angles=False, create_complex=True, n_complex=4):
        """Initializes raw_data data arrays.

        This is an internal method. Note that all arrays must be numpy arrays.

        Args:
            n_pings (int): Number of pings.
            n_samples (int): Number of samples.
            initialize (bool): Set to True to initialize arrays.
            create_power (bool): Set to True to create the power attribute.
            create_angles (bool): Set to True to create the angles_alongship_e
                                  angles_athwartship_e attributes.
            create_complex (bool): Set to True to create the complex attribute.
            n_complex (int): Number of complex values per sample
        """

        # First, create uninitialized arrays.
        self.ping_time = np.empty((n_pings), dtype='datetime64[ms]')

        #  create the arrays that contain references to the async data objects
        self.configuration = np.empty((n_pings), dtype='object')
        self.environment = np.empty((n_pings), dtype='object')
        self.filters = np.empty((n_pings), dtype='object')

        #  the rest of the arrays store syncronous ping data
        self.sample_offset = np.empty((n_pings), np.int32)
        self.channel_mode = np.empty((n_pings), np.int32)
        self.pulse_form = np.empty((n_pings), np.int32)
        self.frequency = np.empty((n_pings), np.float32)
        self.pulse_duration = np.empty((n_pings), np.float32)
        self.sample_interval = np.empty((n_pings), np.float32)
        self.slope = np.empty((n_pings), np.float32)
        self.transmit_power = np.empty((n_pings), np.float32)
        self.sample_count = np.empty((n_pings), np.int32)

        #  and the 2d sample data arrays
        if create_power and self.store_power:
            self.power = np.empty((n_pings, n_samples),
                dtype=self.sample_dtype, order='C')
            self.n_samples = n_samples
            self._data_attributes.append('power')
        if create_angles and self.store_angles:
            self.angles_alongship_e = np.empty((n_pings, n_samples),
                dtype=self.sample_dtype, order='C')
            self._data_attributes.append('angles_alongship_e')
            self.angles_athwartship_e = np.empty((n_pings, n_samples),
                dtype=self.sample_dtype, order='C')
            self._data_attributes.append('angles_athwartship_e')
            self.n_samples = n_samples
        if create_complex and self.store_complex:
            self.complex = np.empty((n_pings, n_samples,n_complex),
                dtype=self.sample_dtype, order='C')
            self._data_attributes.append('complex')
            self.n_complex = n_complex
            self.complex_dtype = np.empty((n_pings), dtype='object')
            self.n_samples = n_samples

        #  update our shape attribute
        self._shape()

        # Check if we should initialize them.
        if initialize:
            self.ping_time.fill(np.datetime64('NaT'))
            self.sample_offset.fill(np.nan)
            self.channel_mode.fill(0)
            self.pulse_form.fill(0)
            self.frequency.fill(np.nan)
            self.pulse_duration.fill(np.nan)
            self.sample_interval.fill(np.nan)
            self.slope.fill(np.nan)
            self.transmit_power.fill(np.nan)
            self.sample_count.fill(0)

            if create_angles and self.store_power:
                self.power.fill(np.nan)
            if create_angles and self.store_angles:
                self.angles_alongship_e.fill(np.nan)
                self.angles_athwartship_e.fill(np.nan)
            if create_complex and self.store_complex:
                self.complex.fill(np.nan)


    def __str__(self):
        """
        Reimplemented string method that provides some basic info about the
        raw_data object.
        """

        # Print the class and address.
        msg = str(self.__class__) + " at " + str(hex(id(self))) + "\n"

        # Print some more info about the EK80.raw_data instance.
        n_pings = len(self.ping_time)
        if n_pings > 0:
            msg = msg + "                   channel: " + self.channel_id + "\n"
            msg = msg + "    frequency (first ping): " + str(
                self.frequency[0]) + "\n"
            msg = msg + " pulse length (first ping): " + str(
                self.pulse_duration[0]) + "\n"
            msg = msg + "           data start time: " + str(
                self.ping_time[0]) + "\n"
            msg = msg + "             data end time: " + str(
                self.ping_time[n_pings-1]) + "\n"
            msg = msg + "           number of pings: " + str(n_pings) + "\n"
            if hasattr(self, 'power'):
                n_pings,n_samples = self.power.shape
                msg = msg + ("    power array dimensions: (" + str(n_pings) +
                             "," + str(n_samples) + ")\n")
            if hasattr(self, 'angles_alongship_e'):
                n_pings,n_samples = self.angles_alongship_e.shape
                msg = msg + ("    angle array dimensions: (" + str(n_pings) +
                             "," + str(n_samples) + ")\n")
            if hasattr(self, 'complex'):
                n_pings,n_samples = self.complex.shape
                msg = msg + ("  complex array dimensions: (" + str(n_pings) +
                             "," + str(n_samples) + ")\n")
        else:
            msg = msg + "  raw_data object contains no data\n"

        return msg


class ek80_calibration(calibration):
    """
    The calibration class contains parameters required for transforming power,
    electrical angle, and complex data to Sv/sv TS/SigmaBS and physical angles.

    When converting raw data to power, Sv/sv, Sp/sp, or to physical angles
    you have the option of passing a calibration object containing the data
    you want used during these conversions. To use this object you create an
    instance and populate the attributes with your calibration data.

    You can provide the data in 2 forms:
        As a scalar - the single value will be used for all pings.
        As a vector - a vector of values as long as the number of pings
            in the raw_data object where the first value will be used
            with the first ping, the second with the second, and so on.

    If you set any attribute to None, that attribute's values will be obtained
    from the raw_data object which contains the value at the time of recording.
    If you do not pass a calibration object to the conversion methods
    *all* of the cal parameter values will be extracted from the raw_data
    object.
    """

    def __init__(self, absorption_method='F&G'):
        '''Create an instance of an ek80_calibration object.

        '''

        #  call the parent init
        super(ek80_calibration, self).__init__(absorption_method=absorption_method)

        # Set up the attributes that are specific to the EK80 system. In general
        # this wttribute names will match the parameter names found within the
        # EK80 formatted .raw file except that

        # Absorption_method stores the string identifying the method used to
        # compute seawater absorption. Unlike ER60, EK80 doesn't compute this
        # and instead provides the data to do it.
        self.absorption_method = absorption_method

        # Create a dict containing the hardware sampling frequencies of various
        # Simrad hardware. In EK80 versions prior to 1.12.2 the rx_sampling_frequency
        # configuration property didn't exist. When these files are read, they use
        # the value here based in the transceiver_type configuration value.
        self.default_sampling_frequency = {'GPT':500000,
                                           'SBT':50000,
                                           'WBAT':1500000,
                                           'WBT TUBE':1500000,
                                           'WBT MINI':1500000,
                                           'WBT':1500000,
                                           'WBT HP':187500,
                                           'WBT LF':93750}

        #  these attributes are properties of the raw_data class
        self._raw_attributes = ['sample_offset', 'channel_mode', 'pulse_form', 'frequency',
                'pulse_duration' ,'sample_interval' ,'slope' ,'sample_count', 'transmit_power',
                'filters']
        self._init_attributes(self._raw_attributes)

        #  these attributes are found in the configuration datagram
        self._config_attributes = ['pulse_duration_fm', 'gain' ,'sa_correction', 'equivalent_beam_angle',
                'angle_sensitivity_alongship', 'angle_sensitivity_athwartship', 'angle_offset_alongship',
                'angle_offset_athwartship', 'beam_width_alongship', 'beam_width_athwartship',
                'directivity_drop_at_2x_beam_width', 'transducer_offset_x', 'transducer_offset_y',
                'transducer_offset_z', 'transducer_alpha_x', 'transducer_alpha_y', 'transducer_alpha_z',
                'transducer_name', 'hw_channel_configuration', 'rx_sample_frequency', 'time_bias',
                'transducer_mounting','transceiver_type','impedance']
        self._init_attributes(self._config_attributes)

        # These attributes are found in the environment datagrams
        self._environment_attributes = ['depth', 'acidity', 'salinity', 'sound_speed', 'temperature',
                'latitude', 'transducer_sound_speed', 'sound_velocity_profile', 'drop_keel_offset',
                'water_level_draft']
        self._init_attributes(self._environment_attributes)


        # Add "special" attributes - These are attributes that require specific handling

        # For the EK80, absorption_coefficient is computed so we compute it when requested
        self.absorption_coefficient = None

        # effective_pulse_length is also computed
        self.effective_pulse_duration = None



    def from_raw_data(self, raw_data, return_indices=None):
        """Populates the calibration object.

        This method uses the values extracted from a raw_data object to
        populate the calibration object.

        Args:
            raw_data (raw_data): The object where parameters will be extracted
                from and used to populate the calibration object.
            return_indices (array): A numpy array of indices to return.
        """

        #  call the parent method
        super(ek80_calibration, self).from_raw_data(raw_data,
                return_indices=return_indices)

        # Handle our special attributes

        # EK80 doesn't store absorption directly, but instead it
        # stores the bits needed to compute it.
        self.absorption_coefficient = self._compute_absorption(raw_data,
            return_indices, self.absorption_method)


    def get_attribute_from_raw(self, raw_data, param_name, return_indices=None):
        """get_attribute_from_raw gets an individual attribute using the data
        within the provided raw_data object.
        """

        #  first call the parent method to get the "standard" attributes
        param_data, return_indices = super(ek80_calibration, self).get_attribute_from_raw(
                raw_data, param_name, return_indices=return_indices)

        # Now handle attributes that need some special handling

        # rx_sample_frequency is a special case because it is a parameter
        # that was recently added to the EK80 raw file configuration datagram
        # and there will be files that do not contain it. In these cases we
        # look up a default value based on the transceiver hardware.
        if param_name == 'rx_sample_frequency':
            #  create the return array
            param_data = np.empty((return_indices.shape[0]), dtype=np.float32)

            #  loop thru the indices extracting the values
            ret_idx = 0
            for idx in return_indices:
                #  check if this config object has the rx_sample_frequency key
                conf_keys = raw_data.configuration[idx].keys()
                if 'rx_sample_frequency' in conf_keys:
                    #  yes - get the value
                    param_data[ret_idx] = raw_data.configuration[idx]['rx_sample_frequency']
                else:
                    # no - this data is older. Get the value from the
                    # default_sampling_frequency dict using the transceiver type as key
                    t_type = raw_data.configuration[idx]['transceiver_type']
                    param_data[ret_idx] = self.default_sampling_frequency[t_type]
                ret_idx += 1

        # These parameters are arrays where we need to extract a single value based
        # on the pulse duration the system is using
        elif param_name in ['sa_correction', 'gain']:
            new_data = np.empty((return_indices.shape[0]), dtype=np.float32)
            # TODO: Need to handle cases where lookup param is from pulse_duration_fm
            for idx, config_obj in enumerate(raw_data.configuration):
                #  param_data will be 1d for data that is constant throughout the raw
                #  object or it will be 2d for data that changes.
                if param_data.ndim > 1:
                    new_data[idx] = param_data[0,config_obj['pulse_duration'] == raw_data.pulse_duration[idx]]
                else:
                     new_data[idx] = param_data[config_obj['pulse_duration'] == raw_data.pulse_duration[idx]][0]
            param_data = new_data


        elif param_name == 'effective_pulse_duration':
            # The EK60 does not use effective_pulse_duration so we only compute
            # it for EK80 hardware
            if self.transceiver_type != 'GPT':
                param_data = simrad_signal_proc.compute_effective_pulse_duration(raw_data, self,
                        return_indices=return_indices)
            else:
                param_data = None


        return param_data

    def __str__(self):
        """Re-implements string method that provides some basic info about
        the ek80_calibration object

        Returns:
            A string with information about the ek80_calibration instance.
        """

        #  print the class and address
        msg = str(self.__class__) + " at " + str(hex(id(self))) + "\n"

        # Create a list of attributes to print out
        attr_to_display = ['frequency','transmit_power','pulse_duration',
                'sample_interval', 'gain', 'sa_correction']

        # And assemble the string
        for param_name in attr_to_display:
            n_spaces = 30 - len(param_name)
            msg += n_spaces * ' ' + param_name
            # Extract data from raw_data attribues
            if hasattr(self, param_name):
                attr = getattr(self, param_name)
                if isinstance(attr, np.ndarray):
                    msg += ' :: array ' + str(attr.size) + ' :: First value: ' + str(attr[0]) + '\n'
                else:
                    if attr:
                            msg += ' :: scalar :: Value: ' + str(attr) + '\n'
                    else:
                        msg += ' :: No value set\n'

        return msg
